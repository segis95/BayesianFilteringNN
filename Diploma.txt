\documentclass[a4paper,12pt]{article}
\usepackage{geometry}           % пакет для задания полей страницы командой \geometry
\geometry{left=3cm,right=1.5cm,top=2cm,bottom=2cm}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{enumerate}
\usepackage{mathtext}           % позволяет использовать русские буквы в формулах
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext,cite,enumerate,float}
\usepackage{indentfirst}        % одинаковый отступ для первого параграфа и всего остального
\usepackage{cite}               % команда /cite{1,2,7,9} даёт ссылки
\usepackage{multirow}           % пакет для объединения строк в таблице: надо указать число строк и ширину столбца
\usepackage{array}              % нужен для создания таблиц
\usepackage{cmap}
\usepackage{mathrsfs}
\usepackage{amsmath}
%\usepackage{algorithm}
%\usepackage[noend]{algpseudocode}
\usepackage{cleveref}
\linespread{1.3}                % полтора интервала. Если 1.6, то два интервала
\pagestyle{plain}               % нумерует страницы

\ifx\pdfoutput\undefined
\usepackage{graphicx}
\else
\usepackage[pdftex]{graphicx}
\fi

\usepackage{epsfig}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\usepackage{tikz}
\usetikzlibrary{shapes,matrix,chains,positioning,decorations.pathreplacing,arrows,intersections}

\graphicspath{{piсtures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{graphicx}

\def\pd{\partial}
\def\ben{\begin{equation}}
\def\enn{\end{equation}}
\def\bcs{\begin{cases}}
\def\ecs{\end{cases}}
\def\ra{\rightarrow}
\def\lquad{\qquad \qquad}


\def\algorithmicrequire{\textbf{Дано:}}
\def\algorithmicensure{\textbf{Выход:}}
\def\algorithmicif{\textbf{если}}
\def\algorithmicthen{\textbf{то}}
\def\algorithmicelse{\textbf{иначе}}
\def\algorithmicelsif{\textbf{иначе если}}
\def\algorithmicfor{\textbf{для}}
\def\algorithmicforall{\textbf{для всех}}
\def\algorithmicdo{}
\def\algorithmicwhile{\textbf{пока}}
\def\algorithmicrepeat{\textbf{повторять}}
\def\algorithmicuntil{\textbf{пока}}
\def\algorithmicloop{\textbf{цикл}}
% переопределение стиля комментариев
\def\algorithmiccomment#1{\quad// {\sl #1}}

\def\nl{\newline}
\def\vs{\vspace{12pt}}
\def\ni{\noindent}

\begin{document}
	
\begin{titlepage}
\begin{center}
Министерство образования и науки Российской Федерации\\
\vspace{10pt}
Федеральное государственное автономное образовательное учреждение\\ высшего образования\\

«Московский физико-технический институт\\

(государственный университет)»\\
\vspace{10pt}
Факультет управления и прикладной математики\\
\vspace{10pt}
Кафедра проблем передачи информации и анализа данных\\
\vspace{\baselineskip}
\vspace{\baselineskip}


\end{center}

\vspace{\baselineskip}
\vspace{\baselineskip}

\begin{center}
\large \bf ОБУЧЕНИЕ ГЛУБИННЫХ НЕЙРОННЫХ СЕТЕЙ НА ОСНОВЕ МЕТОДОВ БАЙЕСОВСКОЙ ФИЛЬТРАЦИИ}
\end{center}



\begin{center}
Выпускная квалификационная работа\\
(бакалаврская работа)
\end{center}


\begin{center}
Направление подготовки: 03.03.01 Прикладные математика и физика
\end{center}





\begin{flushleft}
%{Заведующий кафедрой} \hspace{0.7cm} \makebox[2.5in]{\hrulefill} \hspace{1.5cm} А.Г. Тормасов
\vspace{\baselineskip}

\vspace{\baselineskip}

Выполнил:\\
студент 373 группы \hspace{0.30cm} \makebox[2.0in]{\hrulefill} \hspace{0.2cm}Павлов Сергей Владиславович

\vspace{\baselineskip}

Научный руководитель:\\
к.ф.-м.н.
\hspace{0.65cm} \makebox[2.5in]{\hrulefill} \hspace{0.1cm} Бурнаев Евгений Владимирович
\end{flushleft}

\vspace{\baselineskip}
\vspace{\baselineskip}


\vspace{\baselineskip}
\vspace{\baselineskip}
\vspace{\baselineskip}
\vspace{\baselineskip}
\vspace{\baselineskip}
\vspace{\baselineskip}
\begin{center}
Москва 2017
\end{center}

\end{titlepage}	

\setcounter{page}{2}            % Нумерация страниц начинается с "2"
\tableofcontents	

\newpage

\section{Введение}
\par В настоящее время существуют и активно применяются эффективные методы обучения искусственных нейронных сетей(например, метод обратного распространения ошибки). Однако в ряде задач данные методы оставляют открытым вопрос о времени обучения нейронной сети. Причиной такого поведения зачастую являются сугубо вычислительные аспекты: наличие локальных экстремумов, "паралич" сети. Всё это может привести к неограниченному возрастанию времени обучения сети.  Поэтому имеет смысл рассмативать принципиально иные подходы к обучению искусственных нейронных сетей. В данной работе речь пойдёт о принципиальной возможности применения методов байесовской фильтрации для обучения нейронных сетей. \par Цель работы -- разработка алгоритма обучения, основанного на идее байесовской фильтрации и исследование поведения такого алгоритма на конкретных примерах.

\par Методы исследования:
\begin{enumerate}
  \item построение алгоритма обучения нейронной сети;
  \item написание тестовых программ, реализующих построенный алгоритм;
  \item тестирование данных программ на различных выборках;

\end{enumerate}
Объект исследования — методы байесовской фильтрации.\\
Предмет исследования — искусственные нейронные сети.

\newpage
\section{Математический аппарат нейронных сетей}
\subsection{Задача обучения по прецедентам}
\par  Для начала рассмотрим общую задачу, которую решает нейронная сеть. Пусть $X$ - множество объектов, $Y$ - множество допустимых ответов, $y^*:X \rightarrow Y$ - целевая функция, $X^l = (x_i, y_i)^l_{i=1}$ - обучающая выборка, состоящая из прецедентов $(x_i, y_i)$.
\par Задача обучения по прецедентам заключается в восстановлении зависимости $y^*$ по выборке $X^l$. \cite{vorontsov} Для этого строится решающая функция $a: X \rightarrow Y$, которая приближала бы $y^*$ на всём множестве $X$. Эту функцию также называют алгоритмом, т.к. она должна допускать эффективную компьютерную реализацию.
\par Процесс построения алгоритма называется обучением. Методом обучения называется отображение $\mu: (X, Y)^l \rightarrow A$, которое сопоставляет алгоритм произвольной конечной выборке. В задачах обучения по прецедентам всегда есть два этапа:
\begin{itemize}
  \item этап обучения (метод $\mu$ по выборке $X^l$ строит алгоритм $a = \mu(X^l)$);
  \item этап применения (алгоритм $a$ для новых объектов $x$ выдаёт ответы $a(x)$).
\end{itemize}

\par Одним из классических методов обучения является минимизация эмпирического риска (empirical risk minimization). Для него вводится функция потерь $\mathscr{L}(a,x)$, показывающая величину ошибки алгоритма $a$ на объекте $x$. Ответ $a(x)$ называется корректным, если $\mathscr{L}(a,x) = 0$.
\par Также вводится функционал качества (или эмпирический риск) алгоритма $a$ на выборке $X^l$:

\begin{equation}
 \label{eq:Q}
 \begin{aligned}
  Q(a, X^l) = \frac{1}{l} \sum\limits_{i=1}^l \mathscr{L}(a,x_i).
 \end{aligned}
\end{equation}

\par Метод заключается в минимизации эмпирического риска на заданной выборке $X^l$ по множеству $A$ алгоритмов заданной модели:

\begin{equation}
 \label{eq:risk}
 \begin{aligned}
  \mu(X^l) = arg\min_{a \in A} Q(a, X^l).
 \end{aligned}
\end{equation}

\subsection{Определение и устройство нейронной сети}
\par Перейдём непосредственно к нейронным сетям. 
Процедура, которая используется для процесса обучения, называется алгоритмом обучения.
\par Единицей обработки информации в нейронной сети является нейрон. Его модель показана на рисунке \ref{fig:image1}.

\begin{figure}[h]
\centering
\begin{tikzpicture}[
init/.style={
  draw,
  circle,
  inner sep=2pt,
  font=\Huge,
  join = by -latex
},
squa/.style={
  draw,
  inner sep=2pt,
  font=\Large,
  join = by -latex
},
start chain=2,node distance=13mm
]
\node[on chain=2]
  (x2) {$x_2$};
\node[on chain=2,join=by o-latex]
  {$w_2$};
\node[on chain=2,init] (sigma)
  {$\displaystyle\Sigma$};
\node[on chain=2,squa,label=above:{\parbox{2cm}{\centering Функция \\ активации}}]
  {$\sigma(s)$};
\node[on chain=2,join=by -latex,label=above:{\parbox{2cm}{\centering Выходной \\ сигнал}}]
  {$a$};
\begin{scope}[start chain=1]
\node[on chain=1] at (0,1.5cm)
  (x1) {$x_1$};
\node[on chain=1,join=by o-latex]
  (w1) {$w_1$};
\end{scope}
\begin{scope}[start chain=3]
\node[on chain=3] at (0,-1.5cm)
  (x3) {$x_3$};
\node[on chain=3,label=below:веса,join=by o-latex]
  (w3) {$w_3$};
\end{scope}
\node[label=above:\parbox{2cm}{\centering Порог активации \\ $w_0$}] at (sigma|-w1) (b) {};

\draw[-latex] (w1) -- (sigma);
\draw[-latex] (w3) -- (sigma);
\draw[o-latex] (b) -- (sigma);

\draw[decorate,decoration={brace,mirror}] (x1.north west) -- node[left=8pt] {\parbox{2cm}{\centering Входной \\ сигнал}} (x3.south west);
\end{tikzpicture}

\caption{Структура нейрона}
\label{fig:image1}
\end{figure}

Основными элементами нейрона являются:
\begin{enumerate}
\item Набор синапсов, характеризующихся весами. Если синапсу $i$, связанному с нейроном $k$ на вход подаётся сигнал $x_i$, то сигнал умножается на вес $w_{kj}$.
\item Сумматор, который вычисляет линейную комбинацию сигналов путём сложения значений этих сигналов, умноженных на соответствующий вес синапса нейрона.
\item Функция активации, которая позволяет ограничить амплитуду выходного сигнала нейрона. Как правило, после нормировки диапазон амплитуд выхода нейрона находится в интервале [0,1] или [-1,1].
\end{enumerate}

\par Также в модели нейрона присутствует пороговый элемент (или порог активации), который обозначается $w_0$. Эта величина отражает увеличение или уменьшение входного сигнала, подаваемого на функцию активации. Использование порога обеспечивает эффект афинного преобразования выхода линейного сумматора.

\subsection{Модель МакКаллока-Питтса}
\par Рассмотрим математическую модель нейрона, предложенную МакКаллоком и Питтсом. \cite{vorontsov}
Это алгоритм, который принимает на вход вектор описаний признаков $x=(x^1, x^2, ..., x^n)$. Для простоты считаем, что признаки бинарные. Значения признаков - импульсы, поступающие на вход нейрона через синапсы. Эти импульсы складываются с весами $w_1, ..., w_n$, причём синапс называется возбуждающим, если соответствующий ему вес $w_i>0$, и тормозящим, если $w_i<0$. Если суммарный импульс превышает заданный порог активации $w_0$, то нейрон подаёт на выход 1, иначе он подаёт 0. Таким образом, нейрон занимается вычислением n-арной булевой функции вида
\begin{equation}                % Формула с нумерацией и лейблом "pairs" для ссылки на неё с помощью (\ref{pairs})
 \label{eq3}
 \begin{aligned}                % Нужно для набора многострочных формул; в отличие от array, сохраняет размер символов в дробях и кое-что ещё...
  a(x)=\varphi(\sum\limits_{j=1}^n w_j x_j-w_0),
 \end{aligned}
\end{equation}
где $\varphi(z)=[z\ge0]$ - функция Хэвисайда. Функцию $\varphi$ ещё называют функцией активации.
\par Также модель можно обобщить на случай произвольных входов и выходов и произвольной функции активации. Наиболее часто используются следующие функции $\varphi(z)$:

\begin{itemize}
  \item Функция единичного скачка
    \begin{equation}
    \label{eq4}
    \varphi(z) =
    \begin{cases}
        1, &\text{если $z \ge 0$}\\
        0, &\text{если $z \textless 0$}
    \end{cases}
    \end{equation}

  \item Кусочно-линейная функция
    \begin{equation}
    \label{eq7}
    \varphi(z) =
    \begin{cases}
        1, &\text{$z \ge +\frac{1}{2}$}\\
        |z|, &\text{$-\frac{1}{2} \textless z \textless +\frac{1}{2}$}\\
        0, &\text{$z \le -\frac{1}{2},$}
    \end{cases}
    \end{equation}

  \item Сигмоидальная функция
    \begin{equation}
    \label{eq7}
    \varphi(z) = \frac{1}{1+exp(-\alpha z)},
    \end{equation}
    где $\alpha$ - параметр наклона.
\end{itemize}


\subsection{Стохастический градиентный спуск}
\par Исходя из принципа минимизации эмпирического риска, задачу о настройке весов можно свести к задаче минимизации функционала качества:
\begin{equation}
 \label{eq8}
  Q(w)=\sum\limits_{i=1}^l \mathscr{L}(a(x_i),y_i) \rightarrow \min_{w},
\end{equation}
где $\mathscr{L}(a,y)$ - заданная функция потерь, которая характеризует величину ошибки ответа $a$ при правильном ответе $y$. Воспользуемся методом градиентного спуска. Изменение весов на каждой итерации можно записать следующим образом:
\begin{equation}
 \label{eq9}
  w:=w-\eta\frac{\partial Q}{\partial w},
\end{equation}
где $\eta > 0$ - величина шага в направлении антиградиента. В предположении, что $\mathscr{L}$ и $\varphi$ дифференцируемы, распишем градиент:
\begin{equation}
 \label{eq10}
  w:=w-\eta \sum\limits_{i=1}^l \mathscr{L}'_{a}(a(x_i),y_i)\varphi'(\langle w,x_i \rangle)x_i,
\end{equation}
Вектор весов $w$ можно изменять после предъявления всех $l$ объектов, каждый из которых вносит свой вклад в $w$, а можно обновлять вектор для каждого объекта. Второй способ называется методом стохастического градиента; при этом объекты перебираются в случайном порядке. Таким образом,
\begin{equation}
 \label{eq11}
  w:=w-\eta \mathscr{L}'_{a}(a(x_i),y_i)\varphi'(\langle w,x_i \rangle)x_i,
\end{equation}
\par Приведём алгоритм обучения методом стохастического градиента из \cite{vorontsov}.


\begin{algorithm}[H]
%\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
\SetAlgorithmName{Алгоритм}{алгоритм}{Список алгоритмов}
\SetKwInOut{KwIn}{Вход}
\SetKwInOut{KwOut}{Выход}
\SetKwRepeat{Repeat}{повторять}{до тех пор, пока}
\SetKwComment{Comment}{}{}

\KwIn{$X^l$ - обучающая выборка; \\$\eta$ - темп обучения;}
\KwOut{Синаптические веса $w_0, w_1, ..., w_n$;}
инициализируем веса:\\
$w_j:=random(-\frac{1}{2n},\frac{1}{2n})$;\\
инициализируем текущую оценку функционала:\\
$Q:=\sum\limits_{i=1}^l \mathscr{L}(a(x_i),y_i)$;\\
\Repeat{значение $Q$ не стабилизируется}{
выбрать объект $x_i$ из $X^l$ случайным образом\\
вычислить выходное значение алгоритма $a(x_i)$ и ошибку:\\
$\varepsilon_i:=\mathscr{L}(a(x_i),y_i)$;\\
сделать шаг градиентного спуска:\\
$w:=w-\eta \mathscr{L}'_{a}(a(x_i),y_i)\varphi'(\langle w,x_i \rangle)x_i$;\\
оценить значение функционала:\\
$Q:=\frac{l-1}{l}Q+\frac{1}{l}\varepsilon^2_i$;}
\caption{{} Обучение персептрона методом стохастического градиента}
\label{algo:stochastic}
\end{algorithm}

\subsection{Метод обратного распространения ошибок}
\par На практике часто рассматриваются многослойные нейронные сети, которые, как понятно из названия, состоят из нескольких слоёв нейронов: одного входного, одного выходного и нескольких скрытых. Такие сети применяются для большого числа задач. При этом обучение происходит с помощью метода обратного распространения ошибки (error backpropagation algorithm). \cite{haykin}

\par Приведём описание алгоритма из \cite{vorontsov}. Рассмотрим полную многослойную сеть (т.е. такую сеть, в которой присутствуют все синаптические связи между нейронами предыдущего слоя и следующего слоя) и положим $X=R^n, Y=R^m$.
\par Пусть выходной слой состоит из $M$ нейронов с функциями активации $\sigma_m$ и выходами $a^m, m = 1, ..., M$. Перед ним находится скрытый слой из $H$ нейронов с функциями активации $\sigma_h$ и выходами $u^h, h = 1, ..., H$. Веса связей между двумя слоями будем обозначать $w_{hm}$. Перед скрытым слоем находится ещё один слой (распределительный или скрытый) с выходами $v^j, j = 1, ..., J$ и весами $w_{jh}$.
\par Выходные значения сети на объекте $x_i$ вычисляются как суперпозиция:
\begin{equation}
 \label{eq:12}
  a^m(x_i)=\sigma_m(\sum\limits_{h=0}^H w_{hm}u^h(x_i));\ \ u^h(x_i)=\sigma_h(\sum\limits_{j=0}^J w_{jh}v^j(x_i)).
\end{equation}

\par Запишем функционал среднеквадратичной ошибки для отдельного объекта $x_i$:
\begin{equation}
 \label{eq:13}
  Q(w) = \frac{1}{2} \sum\limits_{m=1}^M (a^m(x_i) - y_i^m)^2.
\end{equation}

\par Выпишем частные производные Q по выходам нейронов для выходного слоя:
\begin{equation}
 \label{eq:14}
  \frac{\partial Q(w)}{\partial a^m} = a^m(x_i) - y_i^m = \varepsilon_i^m.
\end{equation}

\par Теперь продифференцируем $Q$ по выходам скрытого слоя:
\begin{equation}
 \label{eq:15}
  \frac{\partial Q(w)}{\partial u^h} = \sum\limits_{m=1}^M (a^m(x_i)-y_i^m)\sigma'_m w_{hm} = \sum\limits \varepsilon_i^m \sigma'_m w_{hm} = \varepsilon_i^h.
\end{equation}
Назовём эту величину ошибкой сети на скрытом слое.
\par Теперь можно выписать градиент $Q$ по весам:
\begin{equation}
 \label{eq:16}
  \frac{\partial Q(w)}{\partial w_{hm}} = \frac{\partial Q(w)}{\partial a^m} \frac{\partial a^m}{\partial w_{hm}} = \varepsilon_i^m \sigma'_m u^h,\ \ m=1, ..., M,\ \ h=0, ..., H;
\end{equation}

\begin{equation}
 \label{eq:17}
  \frac{\partial Q(w)}{\partial u^h} = \frac{\partial Q(w)}{\partial u^h} \frac{\partial u^h}{\partial w_{jh}} = \varepsilon_i^h \sigma'_h v^j,\ \ h=1, ..., H,\ \ j=0, ..., J;
\end{equation}
и так далее для каждого слоя. Выпишем алгоритм полностью.

\begin{algorithm}[H]
%\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
\SetAlgorithmName{Алгоритм}{алгоритм}{Список алгоритмов}
\SetKwInOut{KwIn}{Вход}
\SetKwInOut{KwOut}{Выход}
\SetKwRepeat{Repeat}{повторять}{до тех пор, пока}
\SetKwComment{Comment}{}{}

\KwIn{$X^l=(x_i,y_i)^l_{i=1}$ - обучающая выборка, $x_i \in R^n, y_i \in R^M$;\\
    $H$ - число нейронов в скрытом слое;\\
    $\eta$ - темп обучения;}

\KwOut{Синаптические веса $w_{jh}, w_{hm}$;}
инициализировать веса небольшими случайными значениями:\\
$w_{jh}:=random(-\frac{1}{2n},\frac{1}{2n})$;\\
$w_{hm}:=random(-\frac{1}{2H},\frac{1}{2H})$;\\
\Repeat{$Q$ не стабилизируется}{
выбрать объект $x_i$ случайным образом\\
прямой ход:\\
$u_i^h :=\sigma_h(\sum\limits_{j=0}^J w_{jh}v^j(x_i))$, для всех $h=1, ..., H$;\\
$a_i^m:=\sigma_m(\sum\limits_{h=0}^H w_{hm}u^h(x_i))$, для всех $m=1,...,M$;\\
$\varepsilon_i^m:=a_i^m-y_i^m$, для всех $m=1,...,M$;\\
$Q_i:=\sum\limits_{m=1}^M (\varepsilon_i^m)^2$\\
обратный ход:\\
$\varepsilon_i^h:=\sum\limits_{m=1}^M \varepsilon_i^m \sigma'_m w_{hm}$, для всех $h=1,...,H$;\\
Градиентный шаг:\\
$w_{hm}:=w_{hm} - \eta \epsilon_i^m \sigma'_m u^h$, для всех $h=0,...,H, m=1,...,M$;\\
$w_{jh}:=w_{jh} - \eta \epsilon_i^h \sigma'_h x^j$, для всех $j=0,...,n, h=1,...,H$;\\
$Q:=\frac{l-1}{l}Q+\frac{1}{l}Q_i$;}
\caption{{} Обучение двухслойной сети методом обратного распространения ошибки}
\label{algo:stochastic}
\end{algorithm}


\subsection{Обобщение и проблема переобучения}
\par Одним из недостатков метода обратного распространения ошибки является то, что сеть способна переобучаться, если чрезмерно увеличивать веса. При таком методе обучения в сеть подаётся обучающая выборка, и с помощью алгоритма вычисляются синаптические веса многослойного персептрона. При этом мы надеемся, что полученная сеть способна к обобщению, т.е. для данных из контрольной выборки, которых она никогда ранее не видела, отображение входа на выход будет корректным. Предполагается, что контрольная выборка взята из той же популяции, что и обучающая.
\par Однако, если сеть обучается на слишком большом количестве примеров, она может "запомнить" примеры обучения. Например, из-за шума она может найти признаки, свойственные обучающей выборке, но не моделируемой функции. В этом случае говорят о переобучении сети. Такие сети теряют способность к обобщению на схожих входных сигналах.\cite{haykin}
\par Для улучшения качества и сходимости градиентного обучения, а также для борьбы с переобучением пользуются сокращением весов.\cite{vorontsov} Идея заключается в добавлении к функционалу $Q(w)$ штрафного слагаемого с целью ограничения роста абсолютных значений весов:
\begin{equation}
 \label{eq:18}
  Q_{\tau}(w) = Q(w) + \frac{\tau}{2}\|w\|^2.
\end{equation}
Пересчитаем градиент:
\begin{equation}
 \label{eq:19}
  \frac{\partial Q_{\tau}(w)}{\partial w} = \frac{\partial Q(w)}{\partial w} + \tau w.
\end{equation}
Веса будут обновляться по формуле
\begin{equation}
 \label{eq:20}
  w:=w(1-\eta\tau)-\eta\frac{\partial Q(w)}{\partial w}
\end{equation}



\section{Постановка задачи в терминах байесовской фильтрации}
\subsection{Общая оптимизационная задача}
\par В данном разделе приведём общую оптимизационную задачу\cite{belom}, которую затем применим к задаче обучения нейронной сети.

\par Введём измеримое пространство $(\Omega, \mathcal{F})$ c фильтрацией $\mathcal{F}:=(\mathcal{F}_r)_{r = 0,1,2,\dots T}, T \in N_+$. Рассмотрим также  случайный процес(управляющий процесс)с $\bf{a}$ $: \Omega \times \{0, \dots, T - 1\} \rightarrow A$, где $(A, \mathcal{B})$ - измеримое пространство. Полагаем, что множество допустимых управлений задаётся $\mathcal{A}$. Задавшись управлениями $\bf{a} = (a_0, a_1, \dots, a_{T-1}) \in \mathcal{A}$, рассмотрим Марковский процесс X со значениями в  некотором измеримом пространстве $(S, \mathcal{S})$ и определённый в вероятностном пространстве  $(\Omega, \mathcal{F},  P^{\bf a})$ с $X_0 = x_0$ п.н. и  с заданной вероятностью перехода:

$${\bf P^{a}}(X_{r+1} \in dy| X_r = x) = P^{a_r}(x, dy), \quad 0 \le r < T .$$ 

Таким образом, предполагается, что условное  распределение $X_{r + 1}$ по $\mathcal{F}_r$ управляется вероятностью $P^{a_r}(X_r, dy)$, которая, в свою очередь, управляется $a_r$. В данных терминах сформулируем основную оптимизационную задачу:

$$ Y_0^* := \sup_{{\bf a} \in \mathcal{A}} E^{\bf a}\left[ \sum_{r = 0}^{T-1}f_r(X_r, a_r)\right], $$ для заданных функций $f_r, \quad r = 0, \dots,  T - 1. $ Можно ещё в большей степени обобщить данную задачу, записав для измеримых функций $f_r : S \times A \rightarrow  \mathbb{R}, g_r : S \rightarrow \mathbb{R}$ и для множества $\mathcal{T} \subset \{0, \dots, T\} $: 

$$  Y_0^* := \sup_{{\bf a} \in \mathcal{A}, \tau \in \mathcal{T} } E^{\bf a}\left[ \sum_{r = 0}^{\tau-1}f_r(X_r, a_r) + g_{\tau}(X_{\tau})\right]. \eqno(20)$$

\subsection{Интерпретация и применение к задаче обучения нейронных сетей}

В терминах предыдущего раздела можно интерпретировать задачу обучения следующим образом. Отметим сразу, что "обучение" будет применяться в смысле отличном от привычного. 

\begin{enumerate}
\item Зафиксируем выход сети Y, для которого будем производить обучение;
\item Пусть в исследуемой сети имеется T слоёв;
\item Будем интерпретировать $X_r$ как вектор значений нейронов на слое r.
\item Будем интерпретировать управляющие параметры переходов $a_r$ как соответствующую пару $\bf (w^r, b^r)$ - матрицы весов перехода к соответствующему слою и пороги активации на данном слое; Это также случайные величины, которые мы охарактеризуем ниже;
\item Обозначим функцию потерь сети $L(X_T,Yy)$, которая вычисляется для выхода последнего слоя сети;
\item Все функции $f_r$ из формулы (20) равны тождественно нулю;
\item $\mathcal{T}$ состоит из одного элемента $T - 1$ и, таким образом в формуле (20) супремум по $\mathcal{T}$ не берётся: $\tau = T-1$. Функция $g_{\tau}(X_{\tau}) = L(X_{T-1}, Y)$.
\end{enumerate}

Таким образом, наша задача принимает вид:

$$  Y_0^* := \sup_{{\bf a} \in \mathcal{A} } E^{\bf a}\left[ L(X_{T-1}, Y)\right]. \eqno(21)$$

Обозначим $\A_r$ есть допустимое множество управлений $\bf a$: $\Omega \times \{r, \dots, T-1\} \rightarrow A$. Введём также случайные величины 

$$  Y_r^* := \sup_{{\bf a} \in \mathcal{A}_r } E^{\bf a}\left[ L(X_{T-1}, Y)|X_r\right], \quad 0 \le r \le T. \eqno(21)$$ и зададим функции

$$h_r^*(x) = \sup_{{\bf a} \in \mathcal{A}_r }E^{\bf a}\left[ L(X_{T-1}, Y)|X_r = x\right], \quad 0 \le r \le T $$


В соответствии с принципом Беллмана(см.\cite{belom}), мы можем записать:

$$Y_r^* = h_r^*(X_r).$$

Это означает следующее: если мы знаем зависимость $h_{r+1}^*(x')$ для всех $x'$, то задача поиска $h_r^*(x)$ сводится к оптимизации по единственному параметру $a_r$:

$$h^*_r(x) = \sup_{a_r}\int P^{a_r}(x, dy)h^*_{r+1}(y)$$.

Таким образом, установлено следующее. 
\newline
Для каждого выхода Y нейронной сети мы можем последовательно, начиная с последнего слоя и заканчивая первым, настроить параметры перехода так, что для каждого входа сети они будут максимизировать искомое математическое ожидание. 

\subsection{Построение алгоритма обучения}

Адаптируем обозначения для большей наглядности их использования для нейронной сети.

\ni Зададимся измеримым пространством $(\Omega, \mathcal{A} = 2^{\Omega})$. 
\nl
\\
Если на этом пространстве задана случайная величина $Y: \Omega \rightarrow (E,\mathcal{B})$, то будем обозначать $\sigma(Y)$ минимальную $\sigma -$алгебру, содержащую семейство множеств $\{\{ Y\in B\},  B \in \mathcal{B}\}$. Аналогичное определение имеет место для конечного набора случайных величин.
\\
 Будем называть её {\bf $\sigma -$алгеброй, порождённой случайной величиной Y}.
\vs

\ni Введём также следующие определения:
\begin{itemize}
  \item Определим последовательности $\bf w$ и $\bf b $ векторов: ${\bf w = (w^1, w^2 \dots )}$ и ${\bf b = (b^1, b^2 \dots )},$ каждый из которых имеет свою фиксированную длину;
  \item Определим последовательность $\bf W$ независимых случайных матриц ${\bf W = (W^1, W^2 \dots ),}$  элементы каждой из которых, выписанные по строкам(сверху вниз) одна за другой в одну строку, образуют многомерную нормально распределённую случайную величину с распределением: $\sim \mathcal{N}(\bf w^i, \mathbb{Id})$;
  \item Определим последовательность $\bf B$ независимых случайных векторов ${\bf B = (B^1, B^2 \dots ),}$ таких, что $\bf B^i \sim \mathcal{N}(\bf b^i, \mathbb{Id})$;
  \item Определим функцию $\Phi((M,Z),X) = sigmoid(MX+Z): \mathbb{R}^{lenght(X)}\rightarrow \mathbb{R}^{length(Z)}$; Размерности элементов входа должны быть согласованы, но не фиксированны; $sigmoid()$ есть функция -- сигмоида.
\end{itemize}
Пусть на этом пространстве $(\Omega,\mathcal{A})$ задана марковская цепь $(X_0, X_1, X_2, \dots)$, которая определяется следующим образом: $$X_{i+1} = \Phi((W^{i+1}, B^{i+1}), X_i),i\ge 0 $$ $$X_0 = const, p.s.$$
Такое определение, безусловно, накладывает дополонительные требования согласования размерностей величин, определённых выше. Размерности векторов $X_i$ могут также меняться в зависимости от i. Такое соотношение действительно определяет марковскую цепь, хотя и не стационарную.

\vs
Для определённой марковской цепи можно ввести понятие фильтрации: последовательность вложенных $\sigma$ - алгебр, определённых следующим образом: $$\mathcal{F}_i = \sigma(X_0, X_1, \dots X_i)$$.
Таким образом, получаем вложенную последовательность $\sigma$-алгебр: $$\mathcal{F}_0 \subseteq \mathcal{F}_1 \subseteq \mathcal{F}_2 \subseteq \dots.$$
\\
Отметим важное свойство фильтрации, которое будет полезно при дальнейшем изложении.
Пусть Y есть случайная величина на $(\Omega, \mathcal{A})$ с конечным мат.ожиданием.Тогда верно:
$$\mathbb{E}\left[\mathbb{E}(Y|\mathcal{F}_{i+1})|\mathcal{F}_{i}\right] = \mathbb{E}\left[ Y|\mathcal{F}_i\right]$$



Зададимся нейронной сетью, содержащей T слоёв(занумеруем их $0,1,2,3,\dots T-1$), в каждом по $dim_i$ ($i\in \{0,1,\dots T-1\}$) нейрона, каждый слой полностью связан со своими соседями. Функцию потерь определим на выходном слое и будем считать квадратичной. Назовём её $L'(X_{T-1}, Y)$. Функцию, обратную по знаку функции потерь, назовём $L = -L'$.
\vs

\ni Тогда, зафиксировав $X_0$ можно интерпретировать $X_i$ как состояние слоя сети с номером i. С учётом определений, данных выше, становится понятно, что работа сети управляется марковским процессом, который в свою очередь управляется наборами случайных величин {\bf W} и  {\bf B }, законы распределения которых в свою очередь зависят от наборов чисел {\bf w} и {\bf b}.
\vs


Это позволяет нам ставить вопрос обучения в следующем ключе: {\bf выбрать значения параметров w и b таким образом, чтобы условное математическое ожидание $\mathbb{E} \left[ L'(X_{T-1},Y(X_0))|X_0 \right] $  было минимальным при каждом значении входа $X_0$}. Формально мы можем написать так: $$\inf_{\bf w,b} \mathbb{E} \left[ L'(X_{T-1},Y(X_0))|X_0 \right] = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|X_0 \right]$$

\ni С Учётом свойства, указанного в конце предыдущей части, мы можем переписать данную задачу в следующем виде:

$$ Z_0(X_0) = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|X_0 \right] = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_0 \right] = \sup_{\bf w,b }\mathbb{E}\left[ \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_1 \right]|\mathcal{F}_0\right]$$

Введём обозначения: $$Z_r(X_r) = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_r \right],$$
$$ {\bf w_r = ( w^{r + 1}, \dots w^{T - 1}) },$$  $${\bf b_r = ( b^{r + 1}, \dots b^{T - 1}) }, $$  $$  r\in \{0\dots T - 1\}$$


При этом становится понятно, что $$Z_r(X_r) = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_r \right] = \sup_{\bf w_r,b_r } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_r \right].$$


При данных обозначениях, продолжим цепочку равенств, котороую начали выше:

$$ Z_0(X_0) = \sup_{\bf w,b }\mathbb{E}\left[ \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_1 \right]\mathcal{F}_0\right] = \sup_{\bf w^1, b^1} \mathbb{E}\left[Z_1(X_1)|X_0\right]$$

Итак, мы получили следующее: $$Z_0(X_0) = \sup_{\bf w^1, b^1} \mathbb{E}\left[Z_1(X_1)|X_0\right],$$ 
где $$Z_r(X_r) = \sup_{\bf w_r,b_r } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_r \right]$$.

Продолжая рекуррентно цепочку равенств, получаем: $$Z_0(X_0) =\sup_{\bf w^1, b^1}\mathbb{E}\left[\sup_{\bf w^2, b^2}\mathbb{E}\left[\sup_{\bf w^3, b^3}\mathbb{E}[\dots \sup_{\bf w_{T-1}, b_{T-1}}\mathbb{E}\left[Z_{T-1}(X_{T-1})|X_{T-1})\right]\dots |X_1\right]|X_0\right] = $$ $$= \sup_{\bf w^1, b^1}\mathbb{E}\left[\sup_{\bf w^2, b^2}\mathbb{E}\left[\sup_{\bf w^3, b^3}\mathbb{E}\left[\dots \sup_{\bf w^{T-1}, b^{T-1}}\mathbb{E}\left[L(X_{T-1},Y(X_0))|X_{T-2}\right]\dots |X_3\right]|X_1\right]|X_0\right] $$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







Как видно из последнего равенства, мы можем обучать нашу сеть(в терминах поставленной задачи) поэтапно, однако начиная с конца. Последовательность действий будет следующей.

\begin{itemize}
  \item[1] Решаем задачу $\sup_{\bf w^{T-1}, b^{T-1}}\mathbb{E}\left[L(X_{T-1},Y(X_0))|X_{T-2}\right]$:
    \begin{itemize}
      \item Находим зависимости минимизирующих параметров от значения $X_{T-2}$:\\ {$\bf w^{T-1}_{opt}(X_{T-2}),b^{T-1}_{opt}(X_{T-2})  $}
      \item Объявляем $ P_{T-2}(X_{T-2}) := \sup_{\bf w^{T-1}, b^{T-1}}\mathbb{E}\left[L(X_{T-1},Y(X_0))|X_{T-2}\right]$
    \end{itemize}
  \item[2] Решаем задачу $\sup_{\bf w^{T-2}, b^{T-2}}\mathbb{E} \left[ P_{T-2}(X_{T-2})|X_{T-3}\right]$:
  \begin{itemize}
    \item Находим зависимости минимизирующих параметров от значения $X_{T-3}$: \\{$\bf w^{T-2}_{opt}(X_{T-3}),b^{T-2}_{opt}(X_{T-3})$}
    \item Объявляем $P_{T-3}(X_{T-3}) := \sup_{\bf w^{T-2}, b^{T-2}}\mathbb{E} \left[ P_{T-2}(X_{T-2})|X_{T-3}\right]$
  \end{itemize}
  \item[$\dots$] $\dots \dots \dots \dots \dots \dots  \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots $
  \item[$(T - 1)$] Решаем задачу $\sup_{\bf w^{1}, b^{1}}\mathbb{E} \left[ P_{1}(X_{1})|X_{0}\right]$:
   \begin{itemize}
    \item Находим зависимости минимизирующих параметров от значения $X_{0}$:\\ {$\bf w^{1}_{opt}(X_{0}),b^{1}_{opt}(X_{0})$}
    \item Объявляем $Z_0(X_0) = P_{0}(X_{0}) := \sup_{\bf w^{1}, b^{1}}\mathbb{E} \left[ P_{1}(X_{1})|X_{0}\right]$
  \end{itemize}

\end{itemize}

\subsection{Практическая формулировка и реализация алгоритма}
\begin{itemize}
  \item Значения $X_0$ и $Y_0(X_0)$ берутся из тренировочного набора данных;
  \item На  шаге $i\in[1,\dots, T - 1]$ оптимизационная задача решается перебором по следующей схеме:
  \begin{itemize}
    \item Сгенерировать набор $\{X_{T-i-1}^j\}_{j=0}^{N}$ из гиперкуба $[0,1]^{dim(X_{T-i-1)}$;
    \item Для каждого из $X_{T-i-1}^j$ генерируем по M значений параметров $\bf w^{T-i-1}_{jk}, b^{T-i-1}_{jk}$, $k\in \{1,\dots, M\}$ из ограниченного гиперкуба;
    \item Для каждой пары параметров $\bf w^{T-i-1}_{jk}, b^{T-i-1}_{jk}$ получаем K реализаций случайных величин: $B^{T-i-1}_{jkl},W^{T-i-1}_{jkl}, l = 1, \dots, K $
    \item Вычисляем эмперическое мат.ожидание по этим K значениям:$$ h^{*,emp}_{T-i-1, jk}(X_{T-i-1}^j):= \frac{1}{K}\sum_{l = 1}^K h^*_{T-i}(\sigma(W^{T-i-1}_{jkl})X_{T-i-1}^j + B^{T-i-1}_{jkl})$$
    \item Выбираем пару параметров $w^{T-i-1}_{jk}, b^{T-i-1}_{jk}$, которая даёт максимум мат.ожидания в предыдущем пункте; обозначим их соответственно $w^{*,T-i-1}_{j}, b^{*,T-i-1}_{j}$;
    \item Строим регрессионную модель для зависимости оптимальных параметров $w^{*,T-i-1}_{j}, b^{*,T-i-1}_{j}$ от значения $X_{T-i-1}^j$; данную модель стараемся строить линейной(линейная регрессия);
  \end{itemize}
  
  \item Результатом обучения является последовательность регрессионных моделей, которые отображают текущее состояние очередного слоя $T-i-1$ сети в оптимальные параметры переходов $w^{*,T-i-1}, b^{*,T-i-1}$
  \item При вычислении прогноза будем полагать случайные величины $\bf W^i, B^i$ равными своим мат.ожиданиям $\bf w^i(X_{i-1}), b^i(X_{i-1})$, полученным последовательно по данному входу $X_0$;
  \item Чтобы сделать прогноз по заданному входу $X_0$ необходимо последовательно вычислить: $\bf w^1(X_0), b^1(X_0),X_1, w^2(X_1), b^2(X_1),X_2\dots X_{T-1}$

\end{itemize}

\subsection{Согласование обучений для различных выходов сети}

Напомним, что до сих пор описанный алгоритм позволяет производить обучение сети для заданного фиксированного выхода Y. Однако, поскольку интерес состоит как раз в том, чтобы строить прогнозы, необходимо описать процедуру, позволяющую соединять воедино результаты обучения сети для различных выходов. Далее, в разделе описания экспериментов мы предложим несколько таких процедур объединения. 


\section{Эксперименты}

\subsection{Задача регрессии}

Отметим сразу три главные отличия архитектуры нейронной сети для задачи регрессии и задачи классификации.

\begin{enumerate}
\item В задаче регрессии выход последнего слоя сети берётся без функции-активатора. Это позволяет сети приближать широкий спектр значений, а не только значения из ограниченного интервала(например, $[0,1]$). 
\item В задаче классификации выходной слой $T-1$ всегда имеет единичную размерность;
\item Функция потерь для задачи регрессии берётся квадратичная: $$L(X_{T-1}, Y) = ||X_{T-1} - Y||^2, $$ а в задаче классификации берётся логарифмическая функция потерь: $$L(X_{T-1}, Y) = -(1-Y)log(1-X_{T-1}) - Ylog(X_{T-1}).$$ При этом в силу сказанного выше для классификации имеет место: $$Y \in \{0,1\}, X_{T-1} \in [0,1].$$
\end{enumerate}
\newline

Зададимся функцией $(1 + \sin x) / 2 $ на отрезке $[-\pi, \pi]$.

Поймём, насколько качественно наш алгоритм способен строить приближения. Для этого применим обучения для различных Y к соответствующим им входам $X_0$. То есть каждому Y соответствует свой $X_0$. Обучив сеть для Y, применим его к $X_0$. Получим одну зелёную точку на графике. Сплошная линия — целевая функция. Пример для  N = 15 , M = 15, K = 5, регрессионные модели в обучениях переходов сети применяются линейные. Архитектура сети: [1,2,2,2,2,2,2,1].
\begin{figure}[h]
\begin{center} \includegraphics[width=0.8\linewidth]{reg1.png}
\end{center}
\end{figure}

Мы видим, что в основном обучение для каждой отдельно взятой точки довольно точно запоминает целевую функцию. Безусловно, поскольку процесс обучения рандомизирован, результаты при перезапуске программы получаются немного различные. Но в целом данный график правильно отражает основную тенденцию.
\newline
Теперь было бы интересно получить процедуру, которая позволила бы объединять результаты нескольких обучений воедино и получать прогнозы для входов вне обучающей выборки.

\subsubsection{Простое усреднение и линейная регрессия}

Предлагается сделать следующее.

\begin{itemize}
  \item Получить обучения(последовательности линейных моделей на слоях) для различных выходов сети: $(M_0^{Y(x)}, \dots, M_{T-2}^{Y(x)})$;
  \item С помощью этих моделей, последовательно из применяя начиная с X, получить для каждой пары $(X,Y)$ последовательность $(X_0^(X,Y)=X, X^(X,Y)_1,\dots , X^(X,Y)_{T-1} )$
  \item Для каждого отдельно взятого слоя i произвести обучение новой линейной регрессионной модели для зависимости коэффиентов перехода от входа данного слоя: $\{(X_i^{(X,Y)}, (w^{i,(X,Y)}, b^{i, (X,Y)}))\}_{(X,Y)\in TrainSet}$. 
  \item Полученная регрессионная модель считается финальной для данного слоя;
\end{itemize}

Было установлено, что если в качестве регрессионной модели выбирать линейную(или обычное усреднений, например), то полученное обучение уничтожает всякую информацию об обучающей выборке. 

\begin{figure}[h]
\begin{center} \includegraphics[width=0.8\linewidth]{reg2.png}
\end{center}
\end{figure}

\subsubsection{Нелинейная регрессия}

Однако ситуацию можно исправить, использовав в качестве регрессионной модели более сложные. Мы будем использовать решающие деревья различной глубины. Из графиков видно, что с ростом глубины решающих деревьев качество прогнозов растёт. 

\begin{figure}[h]
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1.1\linewidth]{reg3.png}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1.2\linewidth]{reg4.png}}
\end{minipage}


\end{figure}

\begin{figure}[h]
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1.1\linewidth]{reg5.png}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1.2\linewidth]{reg6.png}}
\end{minipage}

\end{figure}


Стоит также отметить, что, поскольку в задаче регрессии существует множество возможных выходов Y, проведение процесса обучения для каждого из них оказывается затратным по времени. В то же время для задачи классификации выходов всего два: 0 и 1. Далее мы займёмся исследованием задачи классификации и разработкой процедуры объединения результатов для неё.

\subsubsection{Зависимость результата от архитектуры сети}

В ходе экспериментов была замечена зависимость качества прогнозирующей способности от количества слоёв нейронной сети. Зафиксируем  параметры N = 15 , M = 15, K = 5). Исследуем, как количество слоёв влияет на качество обучения. Глубину решающего возьмём равной 5.

Можно заметить, что с ростом глубины сети качество прогноза сначала улучшается, а затем начинает деградировать.

\begin{figure}[h]
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1.1\linewidth]{reg7.png}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1.2\linewidth]{reg8.png}}
\end{minipage}


\end{figure}

\begin{figure}[h]
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1.1\linewidth]{reg9.png}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1.2\linewidth]{reg10.png}}
\end{minipage}

\end{figure}

\begin{figure}[h!]
\begin{center} \includegraphics[width=0.5\linewidth]{reg11.png}
\end{center}
\end{figure}

\subsection{Классификация}
Перейдём к задаче классификации. Существует ряд причин, по которым задача классификации может быть более перспективной и интересной в рамках нашего исследования, чем задача регрессии.

\begin{itemize}
  \item Процесс обучения повтояется только дважды: для 0 и для 1;
  \item Биполярность обучения может иметь понятную интерпретацию и быть использована для построения метода объединения обучений для 0 и для 1;
\end{itemize}

\subsubsection{Подход #1}

Одной из наших задач будет создание метода обобщения, который по возможности не использовал бы нелинейных регрессионных моделей.

\ni Применим сперва подход, который применялся для задачи регрессии. За тем исключением, что процесс обучения произодится только дважды: для 0 и для 1. 

\ni Зафиксируем архитектуру сети: $[1,5,5,5,5,5,1]$. 

\begin{itemize}
  \item Произвести процесс обучения для 0 и для 1; Получить соответственно две последовательности линейных моделей для переходов сети:$$ {\bf M^1} = (M^1_0, \dots, M^1_{T-2})$$ и $${\bf M^2} = (M^2_0, \dots, M^2_{T-2})$$
  \item Для каждого элемента $(X, Y(X))$($Y\in \{0,1\}$) обучающей выборки сгенерировать две последовательности, выбрав предварительно между $\bf M^1$ и $\bf M^2$ в зависимости от значения Y(0 или 1), 
  $$ (X_0^X = X, X_1^X, X_2^X, \dots X_{T-2}^X )$$ и
  $$\bf  ((w^{0,X}, b^{0,X}), (w^{1,X}, b^{1,X}), \dots w^{T-2,X}, b^{T-2,X}) )$$
  \item Для каждого слоя j построить линейную регрессионную модель для зависимости коэффициентов $\bf ((w^{j,X}, b^{j,X})$ от $X_j^X$ для различных X; получить регрессионную модель $M^*_j$;
  \item Объявить объединённым результатом обучения последовательность регрессионных моделей: $${\bf M^*} = (M_0^*, \dots, M_{T - 2}^*) $$
\end{itemize}


\subsubsection{Подход 2}

\subsubsection{Тестирование алгоритмов}
\ni Для тестирования описанных подходов возьмём 6 наборов данных(для бинарной классификации)из общедоступного реестра http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html :

\begin{enumerate}
\item "diabetes"
\item "breast-cancer"
\item "fourclass"
\item "german.numer"
\item "heart"
\item "liver-disorders"

\end{enumerate}

Данные берутся нормированные на $[-1,1]$ для каждой компоненты входа.

Для каждого из 100 запусков программы данные делятся случайным образом на тренировочную и тестовую подвыборки(каждый раз фиксированного размера). Строятся обучения при помощи описанных методов, а также берётся нейронная сеть в традиционном смысле такой же же архитектуры. Результаты сравниваются.

Приведём сводную таблицу для средних значений 
\newpage
\section{Заключение}
В ходе работы мы:
\begin{itemize}
  \item Построили алгоритм обучения нейронных сетей на основе метода байесовской фильтрации;
  \item Реализовали алгоритм на языке python;
  \item Проделали ряд экспериментов на задачах регрессии и классификации
\end{itemize}
Таким образом, цель работы достигнута.
\par В дальнейшем планируется усовершенствование алгоритма для задачи классификации, тестирование его работы на новых данных, а также оптимизация эффективности его реализации.

\newpage
\begin{thebibliography}{99}
\addcontentsline{toc}{section}{Список литературы}





\bibitem{haykin}
Хайкин, Саймон. Нейронные сети: полный курс, 2-е изд., испр. : Пер. с англ. — М. : 000 "И.Д. Вильяме", 2006. — 1104 с. : ил. — Парал. тит. англ.

\bibitem{bishop}
Bishop C. M. Pattern Recognition and Machine Learning: Springer, 2006. - 749 с.


\bibitem{vorontsov}
Воронцов К. В. Лекции по искусственным нейронным сетям\\
http://www.ccas.ru/voron/download/NeuralNets.pdf


\bibitem{nielsen}
Nielsen M. Neural Networks and Deep Learning\\
http://neuralnetworksanddeeplearning.com/


\bibitem{nielsen}
Nielsen M. Neural Networks and Deep Learning\\
http://neuralnetworksanddeeplearning.com/

\bibitem{belom}
Denis Belomestny, Anastasia Kolodko, and John Schoenmakers
Regression Methods for Stochastic Control Problems and Their Convergence Analysis
http://epubs.siam.org/doi/abs/10.1137/090752651


\end{thebibliography}{}

\end{document}