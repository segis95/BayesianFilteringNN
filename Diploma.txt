\documentclass[a4paper,12pt]{article}
\usepackage{geometry}           % пакет для задания полей страницы командой \geometry
\geometry{left=3cm,right=1.5cm,top=2cm,bottom=2cm}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{enumerate}
\usepackage{mathtext}           % позволяет использовать русские буквы в формулах
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext,cite,enumerate,float}
\usepackage{indentfirst}        % одинаковый отступ для первого параграфа и всего остального
\usepackage{cite}               % команда /cite{1,2,7,9} даёт ссылки
\usepackage{multirow}           % пакет для объединения строк в таблице: надо указать число строк и ширину столбца
\usepackage{array}              % нужен для создания таблиц
\usepackage{cmap}
\usepackage{mathrsfs}
\usepackage{amsmath}
%\usepackage{algorithm}
%\usepackage[noend]{algpseudocode}
\usepackage{cleveref}
\linespread{1.3}                % полтора интервала. Если 1.6, то два интервала
\pagestyle{plain}               % нумерует страницы

\ifx\pdfoutput\undefined
\usepackage{graphicx}
\else
\usepackage[pdftex]{graphicx}
\fi

\usepackage{epsfig}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\usepackage{tikz}
\usetikzlibrary{shapes,matrix,chains,positioning,decorations.pathreplacing,arrows,intersections}

\graphicspath{{piсtures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{graphicx}

\def\pd{\partial}
\def\ben{\begin{equation}}
\def\enn{\end{equation}}
\def\bcs{\begin{cases}}
\def\ecs{\end{cases}}
\def\ra{\rightarrow}
\def\lquad{\qquad \qquad}


\def\algorithmicrequire{\textbf{Дано:}}
\def\algorithmicensure{\textbf{Выход:}}
\def\algorithmicif{\textbf{если}}
\def\algorithmicthen{\textbf{то}}
\def\algorithmicelse{\textbf{иначе}}
\def\algorithmicelsif{\textbf{иначе если}}
\def\algorithmicfor{\textbf{для}}
\def\algorithmicforall{\textbf{для всех}}
\def\algorithmicdo{}
\def\algorithmicwhile{\textbf{пока}}
\def\algorithmicrepeat{\textbf{повторять}}
\def\algorithmicuntil{\textbf{пока}}
\def\algorithmicloop{\textbf{цикл}}
% переопределение стиля комментариев
\def\algorithmiccomment#1{\quad// {\sl #1}}

\def\nl{\newline}
\def\vs{\vspace{12pt}}
\def\ni{\noindent}

\begin{document}
	
\begin{titlepage}
\begin{center}
Министерство образования и науки Российской Федерации\\
\vspace{10pt}
Федеральное государственное автономное образовательное учреждение\\ высшего образования\\

«Московский физико-технический институт\\

(государственный университет)»\\
\vspace{10pt}
Факультет управления и прикладной математики\\
\vspace{10pt}
Кафедра проблем передачи информации и анализа данных\\
\vspace{\baselineskip}
\vspace{\baselineskip}


\end{center}

\vspace{\baselineskip}
\vspace{\baselineskip}

\begin{center}
\large \bf ОБУЧЕНИЕ ГЛУБИННЫХ НЕЙРОННЫХ СЕТЕЙ НА ОСНОВЕ МЕТОДОВ БАЙЕСОВСКОЙ ФИЛЬТРАЦИИ}
\end{center}



\begin{center}
Выпускная квалификационная работа\\
(бакалаврская работа)
\end{center}


\begin{center}
Направление подготовки: 03.03.01 Прикладные математика и физика
\end{center}





\begin{flushleft}
%{Заведующий кафедрой} \hspace{0.7cm} \makebox[2.5in]{\hrulefill} \hspace{1.5cm} А.Г. Тормасов
\vspace{\baselineskip}

\vspace{\baselineskip}

Выполнил:\\
студент 373 группы \hspace{0.30cm} \makebox[2.0in]{\hrulefill} \hspace{0.2cm}Павлов Сергей Владиславович

\vspace{\baselineskip}

Научный руководитель:\\
к.ф.-м.н.
\hspace{0.65cm} \makebox[2.5in]{\hrulefill} \hspace{0.1cm} Бурнаев Евгений Владимирович
\end{flushleft}

\vspace{\baselineskip}
\vspace{\baselineskip}


\vspace{\baselineskip}
\vspace{\baselineskip}
\vspace{\baselineskip}
\vspace{\baselineskip}
\vspace{\baselineskip}
\vspace{\baselineskip}
\begin{center}
Москва 2017
\end{center}

\end{titlepage}	

\setcounter{page}{2}            % Нумерация страниц начинается с "2"
\tableofcontents	

\newpage

\section{Введение}
\par В настоящее время существуют и активно применяются эффективные методы обучения искусственных нейронных сетей(например, метод обратного распространения ошибки). Однако в ряде задач данные методы оставляют открытым вопрос о времени обучения нейронной сети. Причиной такого поведения зачастую являются сугубо вычислительные аспекты: наличие локальных экстремумов, "паралич" сети. Всё это может привести к неограниченному возрастанию времени обучения сети.  Поэтому имеет смысл рассмативать принципиально иные подходы к обучению искусственных нейронных сетей. В данной работе речь пойдёт о принципиальной возможности применения методов байесовской фильтрации для обучения нейронных сетей. \par Цель работы -- разработка алгоритма обучения, основанного на идее байесовской фильтрации и исследование поведения такого алгоритма на конкретных примерах.

\par Методы исследования:
\begin{enumerate}
  \item построение алгоритма обучения нейронной сети;
  \item написание тестовых программ, реализующих построенный алгоритм;
  \item тестирование данных программ на различных выборках;

\end{enumerate}
Объект исследования — методы байесовской фильтрации.\\
Предмет исследования — искусственные нейронные сети.

\newpage
\section{Математический аппарат нейронных сетей}
\subsection{Задача обучения по прецедентам}
\par  Для начала рассмотрим общую задачу, которую решает нейронная сеть. Пусть $X$ - множество объектов, $Y$ - множество допустимых ответов, $y^*:X \rightarrow Y$ - целевая функция, $X^l = (x_i, y_i)^l_{i=1}$ - обучающая выборка, состоящая из прецедентов $(x_i, y_i)$.
\par Задача обучения по прецедентам заключается в восстановлении зависимости $y^*$ по выборке $X^l$. \cite{vorontsov} Для этого строится решающая функция $a: X \rightarrow Y$, которая приближала бы $y^*$ на всём множестве $X$. Эту функцию также называют алгоритмом, т.к. она должна допускать эффективную компьютерную реализацию.
\par Процесс построения алгоритма называется обучением. Методом обучения называется отображение $\mu: (X, Y)^l \rightarrow A$, которое сопоставляет алгоритм произвольной конечной выборке. В задачах обучения по прецедентам всегда есть два этапа:
\begin{itemize}
  \item этап обучения (метод $\mu$ по выборке $X^l$ строит алгоритм $a = \mu(X^l)$);
  \item этап применения (алгоритм $a$ для новых объектов $x$ выдаёт ответы $a(x)$).
\end{itemize}

\par Одним из классических методов обучения является минимизация эмпирического риска (empirical risk minimization). Для него вводится функция потерь $\mathscr{L}(a,x)$, показывающая величину ошибки алгоритма $a$ на объекте $x$. Ответ $a(x)$ называется корректным, если $\mathscr{L}(a,x) = 0$.
\par Также вводится функционал качества (или эмпирический риск) алгоритма $a$ на выборке $X^l$:

\begin{equation}
 \label{eq:Q}
 \begin{aligned}
  Q(a, X^l) = \frac{1}{l} \sum\limits_{i=1}^l \mathscr{L}(a,x_i).
 \end{aligned}
\end{equation}

\par Метод заключается в минимизации эмпирического риска на заданной выборке $X^l$ по множеству $A$ алгоритмов заданной модели:

\begin{equation}
 \label{eq:risk}
 \begin{aligned}
  \mu(X^l) = arg\min_{a \in A} Q(a, X^l).
 \end{aligned}
\end{equation}

\subsection{Определение и устройство нейронной сети}
\par Перейдём непосредственно к нейронным сетям. 
Процедура, которая используется для процесса обучения, называется алгоритмом обучения.
\par Единицей обработки информации в нейронной сети является нейрон. Его модель показана на рисунке \ref{fig:image1}.

\begin{figure}[h]
\centering
\begin{tikzpicture}[
init/.style={
  draw,
  circle,
  inner sep=2pt,
  font=\Huge,
  join = by -latex
},
squa/.style={
  draw,
  inner sep=2pt,
  font=\Large,
  join = by -latex
},
start chain=2,node distance=13mm
]
\node[on chain=2]
  (x2) {$x_2$};
\node[on chain=2,join=by o-latex]
  {$w_2$};
\node[on chain=2,init] (sigma)
  {$\displaystyle\Sigma$};
\node[on chain=2,squa,label=above:{\parbox{2cm}{\centering Функция \\ активации}}]
  {$\sigma(s)$};
\node[on chain=2,join=by -latex,label=above:{\parbox{2cm}{\centering Выходной \\ сигнал}}]
  {$a$};
\begin{scope}[start chain=1]
\node[on chain=1] at (0,1.5cm)
  (x1) {$x_1$};
\node[on chain=1,join=by o-latex]
  (w1) {$w_1$};
\end{scope}
\begin{scope}[start chain=3]
\node[on chain=3] at (0,-1.5cm)
  (x3) {$x_3$};
\node[on chain=3,label=below:веса,join=by o-latex]
  (w3) {$w_3$};
\end{scope}
\node[label=above:\parbox{2cm}{\centering Порог активации \\ $w_0$}] at (sigma|-w1) (b) {};

\draw[-latex] (w1) -- (sigma);
\draw[-latex] (w3) -- (sigma);
\draw[o-latex] (b) -- (sigma);

\draw[decorate,decoration={brace,mirror}] (x1.north west) -- node[left=8pt] {\parbox{2cm}{\centering Входной \\ сигнал}} (x3.south west);
\end{tikzpicture}

\caption{Структура нейрона}
\label{fig:image1}
\end{figure}

Основными элементами нейрона являются:
\begin{enumerate}
\item Набор синапсов, характеризующихся весами. Если синапсу $i$, связанному с нейроном $k$ на вход подаётся сигнал $x_i$, то сигнал умножается на вес $w_{kj}$.
\item Сумматор, который вычисляет линейную комбинацию сигналов путём сложения значений этих сигналов, умноженных на соответствующий вес синапса нейрона.
\item Функция активации, которая позволяет ограничить амплитуду выходного сигнала нейрона. Как правило, после нормировки диапазон амплитуд выхода нейрона находится в интервале [0,1] или [-1,1].
\end{enumerate}

\par Также в модели нейрона присутствует пороговый элемент (или порог активации), который обозначается $w_0$. Эта величина отражает увеличение или уменьшение входного сигнала, подаваемого на функцию активации. Использование порога обеспечивает эффект афинного преобразования выхода линейного сумматора.

\subsection{Модель МакКаллока-Питтса}
\par Рассмотрим математическую модель нейрона, предложенную МакКаллоком и Питтсом. \cite{vorontsov}
Это алгоритм, который принимает на вход вектор описаний признаков $x=(x^1, x^2, ..., x^n)$. Для простоты считаем, что признаки бинарные. Значения признаков - импульсы, поступающие на вход нейрона через синапсы. Эти импульсы складываются с весами $w_1, ..., w_n$, причём синапс называется возбуждающим, если соответствующий ему вес $w_i>0$, и тормозящим, если $w_i<0$. Если суммарный импульс превышает заданный порог активации $w_0$, то нейрон подаёт на выход 1, иначе он подаёт 0. Таким образом, нейрон занимается вычислением n-арной булевой функции вида
\begin{equation}                % Формула с нумерацией и лейблом "pairs" для ссылки на неё с помощью (\ref{pairs})
 \label{eq3}
 \begin{aligned}                % Нужно для набора многострочных формул; в отличие от array, сохраняет размер символов в дробях и кое-что ещё...
  a(x)=\varphi(\sum\limits_{j=1}^n w_j x_j-w_0),
 \end{aligned}
\end{equation}
где $\varphi(z)=[z\ge0]$ - функция Хэвисайда. Функцию $\varphi$ ещё называют функцией активации.
\par Также модель можно обобщить на случай произвольных входов и выходов и произвольной функции активации. Наиболее часто используются следующие функции $\varphi(z)$:

\begin{itemize}
  \item Функция единичного скачка
    \begin{equation}
    \label{eq4}
    \varphi(z) =
    \begin{cases}
        1, &\text{если $z \ge 0$}\\
        0, &\text{если $z \textless 0$}
    \end{cases}
    \end{equation}

  \item Кусочно-линейная функция
    \begin{equation}
    \label{eq7}
    \varphi(z) =
    \begin{cases}
        1, &\text{$z \ge +\frac{1}{2}$}\\
        |z|, &\text{$-\frac{1}{2} \textless z \textless +\frac{1}{2}$}\\
        0, &\text{$z \le -\frac{1}{2},$}
    \end{cases}
    \end{equation}

  \item Сигмоидальная функция
    \begin{equation}
    \label{eq7}
    \varphi(z) = \frac{1}{1+exp(-\alpha z)},
    \end{equation}
    где $\alpha$ - параметр наклона.
\end{itemize}


\subsection{Стохастический градиентный спуск}
\par Исходя из принципа минимизации эмпирического риска, задачу о настройке весов можно свести к задаче минимизации функционала качества:
\begin{equation}
 \label{eq8}
  Q(w)=\sum\limits_{i=1}^l \mathscr{L}(a(x_i),y_i) \rightarrow \min_{w},
\end{equation}
где $\mathscr{L}(a,y)$ - заданная функция потерь, которая характеризует величину ошибки ответа $a$ при правильном ответе $y$. Воспользуемся методом градиентного спуска. Изменение весов на каждой итерации можно записать следующим образом:
\begin{equation}
 \label{eq9}
  w:=w-\eta\frac{\partial Q}{\partial w},
\end{equation}
где $\eta > 0$ - величина шага в направлении антиградиента. В предположении, что $\mathscr{L}$ и $\varphi$ дифференцируемы, распишем градиент:
\begin{equation}
 \label{eq10}
  w:=w-\eta \sum\limits_{i=1}^l \mathscr{L}'_{a}(a(x_i),y_i)\varphi'(\langle w,x_i \rangle)x_i,
\end{equation}
Вектор весов $w$ можно изменять после предъявления всех $l$ объектов, каждый из которых вносит свой вклад в $w$, а можно обновлять вектор для каждого объекта. Второй способ называется методом стохастического градиента; при этом объекты перебираются в случайном порядке. Таким образом,
\begin{equation}
 \label{eq11}
  w:=w-\eta \mathscr{L}'_{a}(a(x_i),y_i)\varphi'(\langle w,x_i \rangle)x_i,
\end{equation}
\par Приведём алгоритм обучения методом стохастического градиента из \cite{vorontsov}.


\begin{algorithm}[H]
%\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
\SetAlgorithmName{Алгоритм}{алгоритм}{Список алгоритмов}
\SetKwInOut{KwIn}{Вход}
\SetKwInOut{KwOut}{Выход}
\SetKwRepeat{Repeat}{повторять}{до тех пор, пока}
\SetKwComment{Comment}{}{}

\KwIn{$X^l$ - обучающая выборка; \\$\eta$ - темп обучения;}
\KwOut{Синаптические веса $w_0, w_1, ..., w_n$;}
инициализируем веса:\\
$w_j:=random(-\frac{1}{2n},\frac{1}{2n})$;\\
инициализируем текущую оценку функционала:\\
$Q:=\sum\limits_{i=1}^l \mathscr{L}(a(x_i),y_i)$;\\
\Repeat{значение $Q$ не стабилизируется}{
выбрать объект $x_i$ из $X^l$ случайным образом\\
вычислить выходное значение алгоритма $a(x_i)$ и ошибку:\\
$\varepsilon_i:=\mathscr{L}(a(x_i),y_i)$;\\
сделать шаг градиентного спуска:\\
$w:=w-\eta \mathscr{L}'_{a}(a(x_i),y_i)\varphi'(\langle w,x_i \rangle)x_i$;\\
оценить значение функционала:\\
$Q:=\frac{l-1}{l}Q+\frac{1}{l}\varepsilon^2_i$;}
\caption{{} Обучение персептрона методом стохастического градиента}
\label{algo:stochastic}
\end{algorithm}

\subsection{Метод обратного распространения ошибок}
\par На практике часто рассматриваются многослойные нейронные сети, которые, как понятно из названия, состоят из нескольких слоёв нейронов: одного входного, одного выходного и нескольких скрытых. Такие сети применяются для большого числа задач. При этом обучение происходит с помощью метода обратного распространения ошибки (error backpropagation algorithm). \cite{haykin}

\par Приведём описание алгоритма из \cite{vorontsov}. Рассмотрим полную многослойную сеть (т.е. такую сеть, в которой присутствуют все синаптические связи между нейронами предыдущего слоя и следующего слоя) и положим $X=R^n, Y=R^m$.
\par Пусть выходной слой состоит из $M$ нейронов с функциями активации $\sigma_m$ и выходами $a^m, m = 1, ..., M$. Перед ним находится скрытый слой из $H$ нейронов с функциями активации $\sigma_h$ и выходами $u^h, h = 1, ..., H$. Веса связей между двумя слоями будем обозначать $w_{hm}$. Перед скрытым слоем находится ещё один слой (распределительный или скрытый) с выходами $v^j, j = 1, ..., J$ и весами $w_{jh}$.
\par Выходные значения сети на объекте $x_i$ вычисляются как суперпозиция:
\begin{equation}
 \label{eq:12}
  a^m(x_i)=\sigma_m(\sum\limits_{h=0}^H w_{hm}u^h(x_i));\ \ u^h(x_i)=\sigma_h(\sum\limits_{j=0}^J w_{jh}v^j(x_i)).
\end{equation}

\par Запишем функционал среднеквадратичной ошибки для отдельного объекта $x_i$:
\begin{equation}
 \label{eq:13}
  Q(w) = \frac{1}{2} \sum\limits_{m=1}^M (a^m(x_i) - y_i^m)^2.
\end{equation}

\par Выпишем частные производные Q по выходам нейронов для выходного слоя:
\begin{equation}
 \label{eq:14}
  \frac{\partial Q(w)}{\partial a^m} = a^m(x_i) - y_i^m = \varepsilon_i^m.
\end{equation}

\par Теперь продифференцируем $Q$ по выходам скрытого слоя:
\begin{equation}
 \label{eq:15}
  \frac{\partial Q(w)}{\partial u^h} = \sum\limits_{m=1}^M (a^m(x_i)-y_i^m)\sigma'_m w_{hm} = \sum\limits \varepsilon_i^m \sigma'_m w_{hm} = \varepsilon_i^h.
\end{equation}
Назовём эту величину ошибкой сети на скрытом слое.
\par Теперь можно выписать градиент $Q$ по весам:
\begin{equation}
 \label{eq:16}
  \frac{\partial Q(w)}{\partial w_{hm}} = \frac{\partial Q(w)}{\partial a^m} \frac{\partial a^m}{\partial w_{hm}} = \varepsilon_i^m \sigma'_m u^h,\ \ m=1, ..., M,\ \ h=0, ..., H;
\end{equation}

\begin{equation}
 \label{eq:17}
  \frac{\partial Q(w)}{\partial u^h} = \frac{\partial Q(w)}{\partial u^h} \frac{\partial u^h}{\partial w_{jh}} = \varepsilon_i^h \sigma'_h v^j,\ \ h=1, ..., H,\ \ j=0, ..., J;
\end{equation}
и так далее для каждого слоя. Выпишем алгоритм полностью.

\begin{algorithm}[H]
%\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
\SetAlgorithmName{Алгоритм}{алгоритм}{Список алгоритмов}
\SetKwInOut{KwIn}{Вход}
\SetKwInOut{KwOut}{Выход}
\SetKwRepeat{Repeat}{повторять}{до тех пор, пока}
\SetKwComment{Comment}{}{}

\KwIn{$X^l=(x_i,y_i)^l_{i=1}$ - обучающая выборка, $x_i \in R^n, y_i \in R^M$;\\
    $H$ - число нейронов в скрытом слое;\\
    $\eta$ - темп обучения;}

\KwOut{Синаптические веса $w_{jh}, w_{hm}$;}
инициализировать веса небольшими случайными значениями:\\
$w_{jh}:=random(-\frac{1}{2n},\frac{1}{2n})$;\\
$w_{hm}:=random(-\frac{1}{2H},\frac{1}{2H})$;\\
\Repeat{$Q$ не стабилизируется}{
выбрать объект $x_i$ случайным образом\\
прямой ход:\\
$u_i^h :=\sigma_h(\sum\limits_{j=0}^J w_{jh}v^j(x_i))$, для всех $h=1, ..., H$;\\
$a_i^m:=\sigma_m(\sum\limits_{h=0}^H w_{hm}u^h(x_i))$, для всех $m=1,...,M$;\\
$\varepsilon_i^m:=a_i^m-y_i^m$, для всех $m=1,...,M$;\\
$Q_i:=\sum\limits_{m=1}^M (\varepsilon_i^m)^2$\\
обратный ход:\\
$\varepsilon_i^h:=\sum\limits_{m=1}^M \varepsilon_i^m \sigma'_m w_{hm}$, для всех $h=1,...,H$;\\
Градиентный шаг:\\
$w_{hm}:=w_{hm} - \eta \epsilon_i^m \sigma'_m u^h$, для всех $h=0,...,H, m=1,...,M$;\\
$w_{jh}:=w_{jh} - \eta \epsilon_i^h \sigma'_h x^j$, для всех $j=0,...,n, h=1,...,H$;\\
$Q:=\frac{l-1}{l}Q+\frac{1}{l}Q_i$;}
\caption{{} Обучение двухслойной сети методом обратного распространения ошибки}
\label{algo:stochastic}
\end{algorithm}


\subsection{Обобщение и проблема переобучения}
\par Одним из недостатков метода обратного распространения ошибки является то, что сеть способна переобучаться, если чрезмерно увеличивать веса. При таком методе обучения в сеть подаётся обучающая выборка, и с помощью алгоритма вычисляются синаптические веса многослойного персептрона. При этом мы надеемся, что полученная сеть способна к обобщению, т.е. для данных из контрольной выборки, которых она никогда ранее не видела, отображение входа на выход будет корректным. Предполагается, что контрольная выборка взята из той же популяции, что и обучающая.
\par Однако, если сеть обучается на слишком большом количестве примеров, она может "запомнить" примеры обучения. Например, из-за шума она может найти признаки, свойственные обучающей выборке, но не моделируемой функции. В этом случае говорят о переобучении сети. Такие сети теряют способность к обобщению на схожих входных сигналах.\cite{haykin}
\par Для улучшения качества и сходимости градиентного обучения, а также для борьбы с переобучением пользуются сокращением весов.\cite{vorontsov} Идея заключается в добавлении к функционалу $Q(w)$ штрафного слагаемого с целью ограничения роста абсолютных значений весов:
\begin{equation}
 \label{eq:18}
  Q_{\tau}(w) = Q(w) + \frac{\tau}{2}\|w\|^2.
\end{equation}
Пересчитаем градиент:
\begin{equation}
 \label{eq:19}
  \frac{\partial Q_{\tau}(w)}{\partial w} = \frac{\partial Q(w)}{\partial w} + \tau w.
\end{equation}
Веса будут обновляться по формуле
\begin{equation}
 \label{eq:20}
  w:=w(1-\eta\tau)-\eta\frac{\partial Q(w)}{\partial w}
\end{equation}



\section{Постановка задачи в терминах байесовской фильтрации}
\subsection{Общая оптимизационная задача}
\par В данном разделе приведём общую оптимизационную задачу\cite{belom}, которую затем применим к задаче обучения нейронной сети.

\par Введём измеримое пространство $(\Omega, \mathcal{F})$ c фильтрацией $\mathcal{F}:=(\mathcal{F}_r)_{r = 0,1,2,\dots T}, T \in N_+$. Рассмотрим также  случайный процес(управляющий процесс)с $\bf{a}$ $: \Omega \times \{0, \dots, T - 1\} \rightarrow A$, где $(A, \mathcal{B})$ - измеримое пространство. Полагаем, что множество допустимых управлений задаётся $\mathcal{A}$. Задавшись управлениями $\bf{a} = (a_0, a_1, \dots, a_{T-1}) \in \mathcal{A}$, рассмотрим Марковский процесс X со значениями в  некотором измеримом пространстве $(S, \mathcal{S})$ и определённый в вероятностном пространстве  $(\Omega, \mathcal{F},  P^{\bf a})$ с $X_0 = x_0$ п.н. и  с заданной вероятностью перехода:

$${\bf P^{a}}(X_{r+1} \in dy| X_r = x) = P^{a_r}(x, dy), \quad 0 \le r < T .$$ 

Таким образом, предполагается, что условное  распределение $X_{r + 1}$ по $\mathcal{F}_r$ управляется вероятностью $P^{a_r}(X_r, dy)$, которая, в свою очередь, управляется $a_r$. В данных терминах сформулируем основную оптимизационную задачу:

$$ Y_0^* := \sup_{{\bf a} \in \mathcal{A}} E^{\bf a}\left[ \sum_{r = 0}^{T-1}f_r(X_r, a_r)\right], $$ для заданных функций $f_r, \quad r = 0, \dots,  T - 1. $ Можно ещё в большей степени обобщить данную задачу, записав для измеримых функций $f_r : S \times A \rightarrow  \mathbb{R}, g_r : S \rightarrow \mathbb{R}$ и для множества $\mathcal{T} \subset \{0, \dots, T\} $: 

$$  Y_0^* := \sup_{{\bf a} \in \mathcal{A}, \tau \in \mathcal{T} } E^{\bf a}\left[ \sum_{r = 0}^{\tau-1}f_r(X_r, a_r) + g_r(X_{\tau})\right]. \eqno(20)$$

\subsection{Интерпретация и применение к задаче обучения нейронных сетей}

В терминах предыдущего раздела можно интерпретировать задачу обучения следующим образом. Отметим сразу, что "обучение" будет применяться в смысле отличном от привычного. 

\begin{enumerate}
\item Зафиксируем выход сети Y, для которого будем производить обучение;
\item Пусть в исследуемой сети имеется T слоёв;
\item Будем интерпретировать $X_r$ как вектор значений нейронов на слое r.
\item Будем интерпретировать управляющие параметры переходов $a_r$ как соответствующую пару $\bf (w^r, b^r)$ - матрицы весов перехода к соответствующему слою и пороги активации на данном слое; Это также случайные величины, которые мы охарактеризуем ниже;
\item Обозначим функцию потерь сети $L(X_T,Yy)$, которая вычисляется для выхода последнего слоя сети;
\item Все функции $f_r$ из формулы (20) равны тождественно нулю;
\item $\mathcal{T}$ состоит из одного элемента $T - 1$ и, таким образом в формуле (20) супремум по $\mathcal{T}$ не берётся: $\tau = T-1$. Функция $g_r(X_{\tau}) = L(X_{T-1}, Y)$.
\end{enumerate}

Таким образом, наша задача принимает вид:

$$  Y_0^* := \sup_{{\bf a} \in \mathcal{A} } E^{\bf a}\left[ L(X_{T-1}, Y)\right]. \eqno(21)$$

Обозначим $\A_r$ есть допустимое множество управлений $\bf a$: $\Omega \times \{r, \dots, T-1\} \rightarrow A$. Введём также случайные величины 

$$  Y_r^* := \sup_{{\bf a} \in \mathcal{A}_r } E^{\bf a}\left[ L(X_{T-1}, Y)|X_r\right], \quad 0 \le r \le T. \eqno(21)$$ и зададим функции

$$h_r^*(x) = \sup_{{\bf a} \in \mathcal{A}_r }E^{\bf a}\left[ L(X_{T-1}, Y)|X_r = x\right], \quad 0 \le r \le T $$

\newpage
В соответствии с принципом Беллмана(см.\cite{belom}), мы можем записать:

$$Y_r^* = h_r^*(X_r).$$

Это означает следующее: если мы знаем зависимость $h_{r+1}^*(x')$ для всех $x'$, то задача поиска $h_r^*(x)$ сводится к оптимизации по единственному параметру $a_r$:

$$h^*_r(x) = \sup_{a_r}\int P^{a_r}(x, dy)h^*_{r+1}(y)$$.

Таким образом, установлено следующее. 
\newline
Для каждого выхода Y нейронной сети мы можем последовательно, начиная с последнего слоя и заканчивая первым, настроить параметры перехода так, что для каждого входа сети они будут максимизировать искомое математическое ожидание. 

\subsection{Построение алгоритма обучения}

Адаптируем обозначения для большей наглядности их использования для нейронной сети.

\ni Зададимся измеримым пространством $(\Omega, \mathcal{A} = 2^{\Omega})$. 
\nl
\\
Если на этом пространстве задана случайная величина $Y: \Omega \rightarrow (E,\mathcal{B})$, то будем обозначать $\sigma(Y)$ минимальную $\sigma -$алгебру, содержащую семейство множеств $\{\{ Y\in B\},  B \in \mathcal{B}\}$. Аналогичное определение имеет место для конечного набора случайных величин.
\\
 Будем называть её {\bf $\sigma -$алгеброй, порождённой случайной величиной Y}.
\vs

\ni Введём также следующие определения:
\begin{itemize}
  \item Определим последовательности $\bf w$ и $\bf b $ векторов: ${\bf w = (w^1, w^2 \dots )}$ и ${\bf b = (b^1, b^2 \dots )},$ каждый из которых имеет свою фиксированную длину;
  \item Определим последовательность $\bf W$ независимых случайных матриц ${\bf W = (W^1, W^2 \dots ),}$  элементы каждой из которых, выписанные по строкам(сверху вниз) одна за другой в одну строку, образуют многомерную нормально распределённую случайную величину с распределением: $\sim \mathcal{N}(\bf w^i, \mathbb{Id})$;
  \item Определим последовательность $\bf B$ независимых случайных векторов ${\bf B = (B^1, B^2 \dots ),}$ таких, что $\bf B^i \sim \mathcal{N}(\bf b^i, \mathbb{Id})$;
  \item Определим функцию $\Phi((M,Z),X) = sigmoid(MX+Z): \mathbb{R}^{lenght(X)}\rightarrow \mathbb{R}^{length(Z)}$; Размерности элементов входа должны быть согласованы, но не фиксированны; $sigmoid()$ есть функция -- сигмоида.
\end{itemize}
Пусть на этом пространстве $(\Omega,\mathcal{A})$ задана марковская цепь $(X_0, X_1, X_2, \dots)$, которая определяется следующим образом: $$X_{i+1} = \Phi((W^{i+1}, B^{i+1}), X_i),i\ge 0 $$ $$X_0 = const, p.s.$$
Такое определение, безусловно, накладывает дополонительные требования согласования размерностей величин, определённых выше. Размерности векторов $X_i$ могут также меняться в зависимости от i. Такое соотношение действительно определяет марковскую цепь, хотя и не стационарную.

\vs
Для определённой марковской цепи можно ввести понятие фильтрации: последовательность вложенных $\sigma$ - алгебр, определённых следующим образом: $$\mathcal{F}_i = \sigma(X_0, X_1, \dots X_i)$$.
Таким образом, получаем вложенную последовательность $\sigma$-алгебр: $$\mathcal{F}_0 \subseteq \mathcal{F}_1 \subseteq \mathcal{F}_2 \subseteq \dots.$$
\\
Отметим важное свойство фильтрации, которое будет полезно при дальнейшем изложении.
Пусть Y есть случайная величина на $(\Omega, \mathcal{A})$ с конечным мат.ожиданием.Тогда верно:
$$\mathbb{E}\left[\mathbb{E}(Y|\mathcal{F}_{i+1})|\mathcal{F}_{i}\right] = \mathbb{E}\left[ Y|\mathcal{F}_i\right]$$



Зададимся нейронной сетью, содержащей T слоёв(занумеруем их $0,1,2,3,\dots T-1$), в каждом по $dim_i$ ($i\in \{0,1,\dots T-1\}$) нейрона, каждый слой полностью связан со своими соседями. Функцию потерь определим на выходном слое и будем считать квадратичной. Назовём её $L'(X_{T-1}, Y)$. Функцию, обратную по знаку функции потерь, назовём $L = -L'$.
\vs

\ni Тогда, зафиксировав $X_0$ можно интерпретировать $X_i$ как состояние слоя сети с номером i. С учётом определений, данных выше, становится понятно, что работа сети управляется марковским процессом, который в свою очередь управляется наборами случайных величин {\bf W} и  {\bf B }, законы распределения которых в свою очередь зависят от наборов чисел {\bf w} и {\bf b}.
\vs


Это позволяет нам ставить вопрос обучения в следующем ключе: {\bf выбрать значения параметров w и b таким образом, чтобы условное математическое ожидание $\mathbb{E} \left[ L'(X_{T-1},Y(X_0))|X_0 \right] $  было минимальным при каждом значении входа $X_0$}. Формально мы можем написать так: $$\inf_{\bf w,b} \mathbb{E} \left[ L'(X_{T-1},Y(X_0))|X_0 \right] = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|X_0 \right]$$

\ni С Учётом свойства, указанного в конце предыдущей части, мы можем переписать данную задачу в следующем виде:

$$ Z_0(X_0) = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|X_0 \right] = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_0 \right] = \sup_{\bf w,b }\mathbb{E}\left[ \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_1 \right]|\mathcal{F}_0\right]$$

Введём обозначения: $$Z_r(X_r) = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_r \right],$$
$$ {\bf w_r = ( w^{r + 1}, \dots w^{T - 1}) },$$  $${\bf b_r = ( b^{r + 1}, \dots b^{T - 1}) }, $$  $$  r\in \{0\dots T - 1\}$$


При этом становится понятно, что $$Z_r(X_r) = \sup_{\bf w,b } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_r \right] = \sup_{\bf w_r,b_r } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_r \right].$$


При данных обозначениях, продолжим цепочку равенств, котороую начали выше:

$$ Z_0(X_0) = \sup_{\bf w,b }\mathbb{E}\left[ \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_1 \right]\mathcal{F}_0\right] = \sup_{\bf w^1, b^1} \mathbb{E}\left[Z_1(X_1)|X_0\right]$$

Итак, мы получили следующее: $$Z_0(X_0) = \sup_{\bf w^1, b^1} \mathbb{E}\left[Z_1(X_1)|X_0\right],$$ 
где $$Z_r(X_r) = \sup_{\bf w_r,b_r } \mathbb{E} \left[ L(X_{T-1},Y(X_0))|\mathcal{F}_r \right]$$.

Продолжая рекуррентно цепочку равенств, получаем: $$Z_0(X_0) =\sup_{\bf w^1, b^1}\mathbb{E}\left[\sup_{\bf w^2, b^2}\mathbb{E}\left[\sup_{\bf w^3, b^3}\mathbb{E}[\dots \sup_{\bf w_{T-1}, b_{T-1}}\mathbb{E}\left[Z_{T-1}(X_{T-1})|X_{T-1})\right]\dots |X_1\right]|X_0\right] = $$ $$= \sup_{\bf w^1, b^1}\mathbb{E}\left[\sup_{\bf w^2, b^2}\mathbb{E}\left[\sup_{\bf w^3, b^3}\mathbb{E}\left[\dots \sup_{\bf w^{T-1}, b^{T-1}}\mathbb{E}\left[L(X_{T-1},Y(X_0))|X_{T-2}\right]\dots |X_3\right]|X_1\right]|X_0\right] $$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\section{Алгоритм обучения сети}

Как видно из последнего равенства, мы можем обучать нашу сеть(в терминах поставленной задачи) поэтапно, однако начиная с конца. Последовательность действий будет следующей.

\begin{itemize}
  \item[1] Решаем задачу $\sup_{\bf w^{T-1}, b^{T-1}}\mathbb{E}\left[L(X_{T-1},Y(X_0))|X_{T-2}\right]$:
    \begin{itemize}
      \item Находим зависимости минимизирующих параметров от значения $X_{T-2}$:\\ {$\bf w^{T-1}_{opt}(X_{T-2}),b^{T-1}_{opt}(X_{T-2})  $}
      \item Объявляем $ P_{T-2}(X_{T-2}) := \sup_{\bf w^{T-1}, b^{T-1}}\mathbb{E}\left[L(X_{T-1},Y(X_0))|X_{T-2}\right]$
    \end{itemize}
  \item[2] Решаем задачу $\sup_{\bf w^{T-2}, b^{T-2}}\mathbb{E} \left[ P_{T-2}(X_{T-2})|X_{T-3}\right]$:
  \begin{itemize}
    \item Находим зависимости минимизирующих параметров от значения $X_{T-3}$: \\{$\bf w^{T-2}_{opt}(X_{T-3}),b^{T-2}_{opt}(X_{T-3})$}
    \item Объявляем $P_{T-3}(X_{T-3}) := \sup_{\bf w^{T-2}, b^{T-2}}\mathbb{E} \left[ P_{T-2}(X_{T-2})|X_{T-3}\right]$
  \end{itemize}
  \item[$\dots$] $\dots \dots \dots \dots \dots \dots  \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots \dots $
  \item[$(T - 1)$] Решаем задачу $\sup_{\bf w^{1}, b^{1}}\mathbb{E} \left[ P_{1}(X_{1})|X_{0}\right]$:
   \begin{itemize}
    \item Находим зависимости минимизирующих параметров от значения $X_{0}$:\\ {$\bf w^{1}_{opt}(X_{0}),b^{1}_{opt}(X_{0})$}
    \item Объявляем $Z_0(X_0) = P_{0}(X_{0}) := \sup_{\bf w^{1}, b^{1}}\mathbb{E} \left[ P_{1}(X_{1})|X_{0}\right]$
  \end{itemize}

\end{itemize}

\section{Практические аспекты}
\begin{itemize}
  \item Значения $X_0$ и $Y_0(X_0)$ будут браться из тренировочного набора данных;
  \item На  шаге с номером i оптимизационная задача решается перебором по следующей схеме:
  \begin{itemize}
    \item Генерируем набор $\{X_{T-i-1}^j\}_{j=0}^{Q}$
    \item Для каждого из $X_{T-i-1}^j$ генерируем по R значений параметров $\bf w^{T-i}_{jk}, b^{T-i}_{jk}, k\in \{1\dots R\}$
    \item Для каждой пары параметров вычисляем эмпирическое мат.ожидание(как среднее по $S = 10$ значениям)
    \item Выбираем пару параметров, которая даёт максимум мат.ожидания;
    \item Строим регрессионную модель для зависимости оптимальных параметров(дающих максимум) от значения $X_{T-i-1}$; данную модель стараемся строить линейной(линейная регрессия);
  \end{itemize}
  \item При вычислении прогноза будем полагать случайные величины $\bf W^i, B^i$ равными своим мат.ожиданиям $\bf w^i(X_{i-1}), b^i(X_{i-1})$, полученным последовательно по данному входу $X_0$(см. следующий пункт для уточнения);
  \item Чтобы сделать прогноз по заданному входу $X_0$ необходимо последовательно вычислить: $\bf w^1(X_0), b^1(X_0),X_1, w^2(X_1), b^2(X_1),X_2\dots X_{T-1}$

\end{itemize}

\section{Заключение}
В ходе работы мы:
\begin{itemize}
  \item написали тестовые программы, потребляющие заранее заданную долю ресурсов;
  \item обучили нейронные сети на выборке, составленной из показаний системных мониторов процессов для тестовых программ;
  \item получили нейронные сети, в первом приближении моделирующие выделение ресурсов ядром Linux.
\end{itemize}
Таким образом, цель работы достигнута.
\par В дальнейшем мы планируем расширение нейронной сети. Каждый из ресурсов характеризуется нескольким числом параметров. Например, процессорное время бывает user-time и system-time, есть различные виды памяти, и чтение с диска/запись на него можно выполнять разными способами. За счёт этих параметров можно увеличить количество входов, выходов и слоёв нейронной сети. Такая улучшенная сеть позволит выявлять больше типов связей, в том числе нелинейные, между ресурсами. Также планируются исследование выделяемых ресурсов в загруженной системе и посещение курса по устройству ядра Linux для более глубокого понимания процесса выделения ресурсов ядром.

\newpage
\begin{thebibliography}{99}
\addcontentsline{toc}{section}{Список литературы}





\bibitem{haykin}
Хайкин, Саймон. Нейронные сети: полный курс, 2-е изд., испр. : Пер. с англ. — М. : 000 "И.Д. Вильяме", 2006. — 1104 с. : ил. — Парал. тит. англ.

\bibitem{bishop}
Bishop C. M. Pattern Recognition and Machine Learning: Springer, 2006. - 749 с.


\bibitem{vorontsov}
Воронцов К. В. Лекции по искусственным нейронным сетям\\
http://www.ccas.ru/voron/download/NeuralNets.pdf


\bibitem{nielsen}
Nielsen M. Neural Networks and Deep Learning\\
http://neuralnetworksanddeeplearning.com/


\bibitem{nielsen}
Nielsen M. Neural Networks and Deep Learning\\
http://neuralnetworksanddeeplearning.com/

\bibitem{belom}
Denis Belomestny, Anastasia Kolodko, and John Schoenmakers
Regression Methods for Stochastic Control Problems and Their Convergence Analysis
http://epubs.siam.org/doi/abs/10.1137/090752651


\end{thebibliography}{}

\end{document}